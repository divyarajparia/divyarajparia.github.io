<!-- projects.html -->
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Projects - Divya Rajparia</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <nav>
    <ul style="list-style: none; display: flex; gap: 20px; padding: 10px; background-color: #f2f2f2;">
      <li><a href="index.html">Home</a></li>
      <li><a href="resume.html">Resume</a></li>
      <li><a href="projects.html" class="active">Projects</a></li>
      <li><a href="timeline.html">Timeline</a></li>
      <li><a href="extracurriculars.html">Extracurriculars</a></li>
      <li><a href="contact.html">Contact</a></li>
    </ul>
  </nav>

  <main>
    <h1>Projects</h1>

    <section>
      <h2>Enhancing Tumor Segmentation using Synthetic Data</h2>
      <p>
        I am currently working as a research intern at the Laboratory for Machine Learning, Health, and Biomedicine at the University of Southern California. The goal of the project is to make tumor segmentation in medical images faster and more reliable. Annotating medical images manually takes up a lot of time for doctors, so we are building models to automate this task.
      </p>
      <p>
        A common problem in this area is that models trained on one dataset often fail when tested on another due to domain shifts. To solve this, we are generating synthetic data to train the model so it learns to generalize across different datasets. We are applying this to breast and lung cancer scans to build a model that can work reliably in real clinical settings.
      </p>
    </section>

    <section>
      <h2>DES: Dynamic Expert Saturation (Continual Learning)</h2>
      <p>
        This project was done at IIT Hyderabad as part of my research in continual learning, which is a way to train machine learning models gradually over time without forgetting past knowledge. Most existing methods assume that the data is balanced and that old samples are available — which is not realistic in practice.
      </p>
      <p>
        We proposed a new learning setup called AFCIL (Assumption-Free Class-Incremental Learning) that removes these assumptions. Our method does not require access to stored data and works even when the data is imbalanced. It also works with modern pre-trained models like CLIP.
      </p>
      <p>
        We introduced a two-stage training method called Dynamic Expert Saturation. In the first stage, the model learns the common classes. In the second stage, it gradually adapts to rare classes by adjusting the expert components. This setup naturally handles class imbalance and avoids forgetting.
      </p>
      <p>
        We used PyTorch and CLIP, with lightweight MLP adapters. Our method achieved state-of-the-art results on CIFAR100-LT and ImageNet-LT, beating previous methods like DualPrompt, CODA, and MoE-Adapter by up to 6% in accuracy.
      </p>
      <p>
        <a href="Divya_Poster Final.pdf" target="_blank">Download Poster</a>
      </p>
    </section>

    <section>
      <h2>Making Vision Transformers More Human-Like</h2>
      <p>
        This was a research project at IIT Hyderabad, submitted to NeurIPS 2025. We wanted to understand how Vision Transformers (ViTs) see and process images, and whether their behavior could be made more interpretable — similar to how humans recognize images from parts.
      </p>
      <p>
        We built a framework using wavelet transforms to break down images into smaller meaningful parts. We then checked whether ViTs could put these parts back together using simple linear combinations. We trained models in PyTorch and ran large experiments on the ImageNet dataset.
      </p>
      <p>
        We found that ViTs do show compositional behavior in deeper layers, and that linear combinations of these parts closely match the original representations. Our results held even when we added noise or compressed the images, suggesting that the behavior is robust.
      </p>
      <p>
        <a href="Down_the_Rabbit_Hole_of_Vision_Transformers.pdf" target="_blank">Download Paper</a>
      </p>
    </section>

  </main>
</body>
</html>
